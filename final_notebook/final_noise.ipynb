{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDNN is available! \n",
      "DirectML is not available, using CPU/GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bjark\\OneDrive - Aarhus universitet\\InTooDeep_project\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "import warnings\n",
    "# Suppress FutureWarning specifically from torch.load\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################### GPU ##########################\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.backends.cudnn.is_available()==True:\n",
    "    print('CUDNN is available! ')\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "try:\n",
    "    import torch_directml\n",
    "    device = torch_directml.device()\n",
    "    print(\"DirectML is available, using DirectML\")\n",
    "except:\n",
    "    print(\"DirectML is not available, using CPU/GPU\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "import windturbine_final as wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet34 = torchvision.models.resnet34(weights=False)\n",
    "ResNet34.fc = torch.nn.Linear(in_features=512,out_features=2,bias=True)\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet34.to(device)\n",
    "# Print summary for a (3, 300, 300) input\n",
    "summary(model, input_size=(3, 300, 300), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image):\n",
    "    image = np.array(image)\n",
    "    image = image[225:525,490:790]\n",
    "    \n",
    "    # Convert back to PIL Image for further transforms\n",
    "    image = Image.fromarray(image)\n",
    "    \n",
    "    # Compose transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "def transform_noise(image):\n",
    "    # Get either 0 or 1\n",
    "    noise = np.random.randint(0, 2)\n",
    "    if noise == 0:\n",
    "        # Get 2 random numbers between -50 and 50\n",
    "        x,y = np.random.randint(-50, 50, 2)\n",
    "\n",
    "        # Convert image to array\n",
    "        image = np.array(image)\n",
    "        image = image[225+x:525+x,490+y:790+y]\n",
    "\n",
    "        # Convert back to PIL Image for further transforms\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        # Compose transformations\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  # Convert to tensor\n",
    "        ])\n",
    "    else:\n",
    "        # Get a random number between 400 and 720\n",
    "        x = np.random.randint(400, 720)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.CenterCrop(x),\n",
    "            transforms.Resize(300),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    return transform(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 18000\n",
      "Model not found, training from scratch\n"
     ]
    }
   ],
   "source": [
    "angle_type = \"both\"\n",
    "batch_size = 16\n",
    "images_num = 1\n",
    "base_angle_range = [0,360]\n",
    "model = ResNet34\n",
    "lr = 1e-2\n",
    "epochs = 40\n",
    "accu_th = [20,10,5]\n",
    "model_name = \"final_models/ResNet34_final_noise.pth\"\n",
    "\n",
    "wind_dataset = wt.WindTurbineDataset(csv_file='rotations_w_images_long.csv', root_dir='data/', \n",
    "                                     images_num=images_num, transform=transform_noise, angle_type=angle_type, base_angle_range=base_angle_range)\n",
    "print(f\"Dataset size: {len(wind_dataset)}\")\n",
    "\n",
    "train_dataset, test_dataset = wt.WindTurbineDataloader.train_test_split(wind_dataset, test_size=0.2)\n",
    "trainloader = wt.WindTurbineDataloader.dataloader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = wt.WindTurbineDataloader.dataloader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_name, map_location=torch.device(\"cpu\")))\n",
    "    print(\"Model loaded successfully\")\n",
    "except:\n",
    "    print(\"Model not found, training from scratch\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = wt.AngularVectorLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#Scheduler\n",
    "schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=np.sqrt(0.1), patience=2, threshold=0.0001)\n",
    "\n",
    "#Trainer\n",
    "trainer = wt.Trainer(model, trainloader, testloader, criterion, optimizer,device, \n",
    "                     epochs=epochs, accu_th=accu_th, angle_type=angle_type, \n",
    "                     schedular=schedular, minimal=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet34 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.train_model()\n",
    "\n",
    "# Plot the training and testing loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Make subplot with loss and accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(trainer.train_loss, label=\"Train Loss\")\n",
    "plt.plot(trainer.test_loss, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "if not trainer.minimal:\n",
    "    # Make subplot with loss and accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(trainer.train_accuracy, label=\"Train Accuracy\")\n",
    "    plt.plot(trainer.test_accuracy, label=\"Test Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.to(\"cpu\").state_dict(), model_name)\n",
    "print(\"Model saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "results = trainer.test_model(model.to(device), wind_dataset, angle_type=angle_type)\n",
    "# Sort the results by base angle\n",
    "results_sorted = results.sort_values(by=\"Base_Angle\")\n",
    "\n",
    "# Plot the results\n",
    "if angle_type == \"both\" or angle_type == \"base_angle\":\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.stem(results_sorted[\"Base_Angle\"], results_sorted[\"Base_Angle_Error\"], label=\"Base Angle Error\")\n",
    "    plt.xlabel(\"Base Angle\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "if angle_type == \"both\" or angle_type == \"blade_angle\":\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.stem(results_sorted[\"Base_Angle\"], results_sorted[\"Blade_Angle_Error\"], label=\"Blade Angle Error\")\n",
    "    plt.xlabel(\"Blade Angle\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
